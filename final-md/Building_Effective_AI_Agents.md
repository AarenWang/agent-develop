# Building Effective AI Agents

> 来源：https://www.anthropic.com/research/building-effective-agents


## 核心速览 (TL;DR)
        - 降价内容：
在过去的一年里，我们与数十个团队合作，跨行业构建大型语言模型 (LLM) 代理。
- 始终如一，最成功的实现并不使用复杂的框架或专门的库。
- 相反，他们使用简单、可组合的模式进行构建。

降价内容：
在过去的一年里，我们与数十个团队合作，跨行业构建大型语言模型 (LLM) 代理。始终如一，最成功的实现并不使用复杂的框架或专门的库。相反，他们使用简单、可组合的模式进行构建。

在这篇文章中，我们分享了我们从与客户和建筑代理合作中学到的知识，并为开发商提供构建有效代理的实用建议。

什么是代理？
----------------

“代理”可以通过多种方式定义。一些客户将代理定义为完全自主的系统，可以长时间独立运行，使用各种工具完成复杂的任务。其他人使用该术语来描述遵循预定义工作流程的更具规范性的实现。在 Anthropic，我们将所有这些变体归类为 **代理系统**，但在 **工作流程 ** 和 **代理** 之间划出了重要的架构区别：

* **工作流程**是通过预定义的代码路径编排法学硕士和工具的系统。
* **代理**，另一方面，是法学硕士动态指导自己的流程和工具使用的系统，保持对他们如何完成任务的控制。

下面，我们将详细探讨这两种类型的代理系统。在附录 1（“实践中的代理”）中，我们描述了客户发现使用此类系统具有特殊价值的两个领域。

何时（以及何时不）使用代理
---------------------------------

当使用法学硕士构建应用程序时，我们建议尽可能寻找最简单的解决方案，并且仅在需要时增加复杂性。这可能意味着根本不构建代理系统。代理系统通常会以延迟和成本来换取更好的任务性能，您应该考虑这种权衡何时有意义。

当需要更高的复杂性时，工作流为明确定义的任务提供可预测性和一致性，而当大规模需要灵活性和模型驱动的决策时，代理是更好的选择。然而，对于许多应用程序来说，通过检索和上下文示例来优化单个 LLM 调用通常就足够了。

何时以及如何使用框架
------------------------------------------

有许多框架可以使代理系统更容易实现，包括：

* [Claude Agent SDK](https://platform.claude.com/docs/en/agent-sdk/overview)；
* [AWS 的 Strands Agent SDK](https://strandsagents.com/latest/)；
* [Rivet](https://rivet.ironcladapp.com/)，拖放 GUI LLM 工作流程构建器；和
* [Vellum](https://www.vellum.ai/)，另一个用于构建和测试复杂工作流程的 GUI 工具。

这些框架通过简化标准低级任务（例如调用 LLM、定义和解析工具以及将调用链接在一起）使入门变得容易。然而，它们经常创建额外的抽象层，这些抽象层可能会掩盖底层的提示和响应，从而使它们更难以调试。当更简单的设置就足够时，它们还可能会增加复杂性。

我们建议开发人员从直接使用 LLM API 开始：许多模式可以通过几行代码实现。如果您确实使用框架，请确保您了解底层代码。对底层内容的错误假设是客户错误的常见来源。

请参阅我们的 [cookbook](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents) 了解一些示例实现。

构建块、工作流程和代理
--------------------------------------

在本节中，我们将探讨我们在生产中看到的代理系统的常见模式。我们将从我们的基础构建块——增强的法学硕士——开始，并逐步增加复杂性，从简单的组合工作流程到自主代理。

### 构建模块：增强法学硕士代理系统的基本构建模块是通过检索、工具和记忆等增强功能增强的法学硕士。我们当前的模型可以积极使用这些功能——生成自己的搜索查询、选择适当的工具以及确定要保留哪些信息。

![图片1](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2Fd3083d3f40bb2b6f477901cc9a240738d3dd1371-2401x1000.png&w=3840&q=75)

增强型法学硕士

我们建议重点关注实施的两个关键方面：根据您的特定用例定制这些功能，并确保它们为您的法学硕士提供简单且记录良好的界面。虽然实现这些增强的方法有很多，但一种方法是通过我们最近发布的[模型上下文协议](https://www.anthropic.com/news/model-context-protocol)，它允许开发人员通过简单的[客户端实现](https://modelcontextprotocol.io/tutorials/building-a-client#building-mcp-clients)与不断增长的第三方工具生态系统集成。

对于本文的其余部分，我们将假设每个 LLM 调用都可以访问这些增强功能。

### 工作流程：提示链接

提示链接将任务分解为一系列步骤，其中每个 LLM 调用都会处理前一个步骤的输出。您可以在任何中间步骤上添加编程检查（请参见下图中的“门”），以确保流程仍按计划进行。

![图片2](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F7418719e3dab222dccb379b8879e1dc08ad34c78-2401x1000.png&w=3840&q=75)

提示链接工作流程

**何时使用此工作流程：** 此工作流程非常适合任务可以轻松、干净地分解为固定子任务的情况。主要目标是通过使每个 LLM 调用变得更容易，来权衡延迟以获得更高的准确性。

**提示链接有用的示例：**

* 生成营销文案，然后将其翻译成其他语言。
* 编写文档大纲，检查大纲是否符合一定标准，然后根据大纲编写文档。

### 工作流程：路由

路由对输入进行分类并将其引导至专门的后续任务。此工作流程允许分离关注点并构建更专业的提示。如果没有此工作流程，针对一种输入的优化可能会损害其他输入的性能。

![图片3](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F5c0c0e9fe4def0b584c04d37849941da55e5e71c-2401x1000.png&w=3840&q=75)

路由工作流程

**何时使用此工作流程：** 路由非常适合复杂的任务，其中存在更好单独处理的不同类别，并且可以通过 LLM 或更传统的分类模型/算法准确处理分类。

**路由有用的示例：**

* 将不同类型的客户服务查询（一般问题、退款请求、技术支持）引导到不同的下游流程、提示和工具中。
* 将简单/常见问题路由到更小的、经济高效的模型（如 Claude Haiku 4.5），将困难/不寻常的问题路由到更强大的模型（如 Claude Sonnet 4.5），以优化最佳性能。

### 工作流程：并行化

法学硕士有时可以同时完成一项任务，并以编程方式汇总其输出。此工作流程（并行化）体现在两个关键变体中：

* **分段**：将任务分解为并行运行的独立子任务。
* **投票：** 多次运行相同的任务以获得不同的输出。

![图片4](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F406bb032ca007fd1624f261af717d70e6ca86286-2401x1000.png&w=3840&q=75)

并行化工作流程**何时使用此工作流程：** 当划分的子任务可以并行化以提高速度时，或者当需要多个视角或尝试以获得更高置信度的结果时，并行化是有效的。对于具有多种考虑因素的复杂任务，当每个考虑因素都由单独的 LLM 调用处理时，LLM 通常会表现得更好，从而允许将注意力集中在每个特定方面。

**并行化有用的示例：**

* **切片**：
    * 实施护栏，其中一个模型实例处理用户查询，而另一个模型实例则筛选不适当的内容或请求。这往往比使用相同的 LLM 调用处理护栏和核心响应的效果更好。
    * 自动评估 LLM 性能，其中每个 LLM 调用根据给定提示评估模型性能的不同方面。

* **投票**：
    * 检查一段代码是否存在漏洞，其中有几个不同的提示会检查并标记代码（如果发现问题）。
    * 评估某条内容是否不当，通过多个提示评估不同方面或要求不同的投票阈值来平衡误报和漏报。

### 工作流程：Orchestrator-workers

在协调者-工作人员工作流程中，中央法学硕士动态分解任务，将它们委托给工作人员法学硕士，并综合其结果。

![图片5](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F8985fc683fae4780fb34eab1365ab78c7e51bc8e-2401x1000.png&w=3840&q=75)

协调者-工作人员工作流程

**何时使用此工作流程：** 此工作流程非常适合您无法预测所需子任务的复杂任务（例如，在编码中，需要更改的文件数量以及每个文件中更改的性质可能取决于任务）。虽然它在拓扑上相似，但与并行化的主要区别在于它的灵活性——子任务不是预先定义的，而是由协调器根据特定输入确定。

** Orchestrator-Workers 有用的示例：**

* 每次对多个文件进行复杂更改的编码产品。
* 搜索任务涉及从多个来源收集和分析信息以获取可能的相关信息。

### 工作流程：评估器-优化器

在评估器-优化器工作流程中，一个 LLM 调用生成响应，而另一个调用则在循环中提供评估和反馈。

![图片6](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F14f51e6406ccb29e695da48b17017e899a6119c7-2401x1000.png&w=3840&q=75)

评估器-优化器工作流程

**何时使用此工作流程：** 当我们有明确的评估标准并且迭代细化提供可衡量的价值时，此工作流程特别有效。良好契合的两个标志是，首先，当人们清楚地表达他们的反馈时，LLM 的反应可以得到明显改善；其次，法学硕士可以提供此类反馈。这类似于人类作家在制作精美文档时可能经历的迭代写作过程。

**评估器优化器有用的示例：**

* 文学翻译中的细微差别是译者法学硕士最初可能无法捕捉到的，但评估者法学硕士可以提供有用的批评。
* 复杂的搜索任务，需要多轮搜索和分析来收集全面的信息，评估者决定是否需要进一步搜索。

### 代理随着法学硕士在关键能力方面的成熟——理解复杂的输入、参与推理和规划、可靠地使用工具以及从错误中恢复，代理正在生产中出现。代理通过人类用户的命令或与人类用户的交互式讨论开始工作。一旦任务明确，智能体就会独立计划和操作，并有可能返回人类以获取进一步的信息或判断。在执行过程中，代理在每个步骤（例如工具调用结果或代码执行）中从环境中获取“基本事实”以评估其进度至关重要。然后，特工可以在检查站或遇到拦截者时暂停以获取人工反馈。任务通常在完成后终止，但通常还包含停止条件（例如最大迭代次数）以保持控制。

代理可以处理复杂的任务，但它们的实现通常很简单。他们通常只是法学硕士，使用基于循环环境反馈的工具。因此，清晰且深思熟虑地设计工具集及其文档至关重要。我们在附录 2（“提示设计您的工具”）中详细介绍了工具开发的最佳实践。

![图片7](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F58d9f10c985c4eb5d53798dea315f7bb5ab6249e-2401x1000.png&w=3840&q=75)

自主代理

**何时使用代理：** 代理可用于解决难以或不可能预测所需步骤数以及无法硬编码固定路径的开放式问题。法学硕士可能会运作很多轮，你必须对其决策有一定程度的信任。代理的自主性使它们成为在可信环境中扩展任务的理想选择。

代理的自主性意味着更高的成本，并且可能会出现复合错误。我们建议在沙盒环境中进行广泛的测试，并配备适当的护栏。

**代理有用的示例：**

以下示例来自我们自己的实现：

* 用于解决 [SWE-bench 任务](https://www.anthropic.com/research/swe-bench-sonnet) 的编码代理，其中涉及根据任务描述对许多文件进行编辑；
* 我们的[“计算机使用”参考实现](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)，其中 Claude 使用计算机来完成任务。

![图片8](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages% 2F4zrzovbb%2F网站%2F4b9a1f4eb63d5962a6e1746ac26bbc857cf3474f-2400x1666.png&w=3840&q=75)

编码代理的高级流程

组合和定制这些模式
----------------------------------------------------

这些构建块不是规定性的。它们是开发人员可以塑造和组合以适应不同用例的常见模式。与任何法学硕士功能一样，成功的关键是衡量性能和迭代实施。重复一遍：只有当复杂性明显改善结果时，您才应该考虑增加复杂性。

总结
--------

法学硕士领域的成功并不在于构建最复杂的系统。这是关于构建满足您需求的_正确_系统。从简单的提示开始，通过综合评估对其进行优化，仅在简单的解决方案无法满足要求时才添加多步骤代理系统。

在实施代理时，我们尝试遵循三个核心原则：

1. 保持代理设计的**简单性**。
2. 通过明确显示代理的规划步骤来优先考虑**透明度**。
3. 通过彻底的工具**文档和测试**精心设计您的代理计算机接口 (ACI)。

框架可以帮助您快速入门，但在转向生产时请毫不犹豫地减少抽象层并使用基本组件进行构建。通过遵循这些原则，您可以创建不仅功能强大而且可靠、可维护且受到用户信任的代理。

### 致谢由埃里克·施伦茨和巴里·张撰写。这项工作借鉴了我们在 Anthropic 建立代理的经验以及我们的客户分享的宝贵见解，对此我们深表感谢。

附录1：代理实践
------------------------------------------

我们与客户的合作揭示了人工智能代理的两个特别有前途的应用，它们证明了上述模式的实际价值。这两个应用程序都说明了代理如何为需要对话和行动的任务增加最大价值，具有明确的成功标准，启用反馈循环，并集成有意义的人工监督。

### A. 客户支持

客户支持通过工具集成将熟悉的聊天机器人界面与增强的功能结合起来。这对于更多开放式代理来说是自然的选择，因为：

* 支持自然地遵循对话流程的交互，同时需要访问外部信息和操作；
* 可以集成工具来提取客户数据、订单历史记录和知识库文章；
* 退款或更新机票等操作可以通过编程方式处理；和
* 成功可以通过用户定义的解决方案来明确衡量。

一些公司已经通过基于使用的定价模型证明了这种方法的可行性，该模型仅对成功的解决方案收费，显示出对其代理有效性的信心。

### B. 编码代理

软件开发领域已显示出法学硕士功能的巨大潜力，其功能从代码完成发展到自主解决问题。代理特别有效，因为：

* 代码解决方案可通过自动化测试进行验证；
* 代理可以使用测试结果作为反馈来迭代解决方案；
* 问题空间定义明确且结构合理；和
* 输出质量可以客观衡量。

在我们自己的实现中，代理现在可以仅根据拉取请求描述来解决 [SWE-bench Verified](https://www.anthropic.com/research/swe-bench-sonnet) 基准中的实际 GitHub 问题。然而，虽然自动化测试有助于验证功能，但人工审查对于确保解决方案符合更广泛的系统要求仍然至关重要。

附录 2：快速设计您的工具
----------------------------------------------------

无论您正在构建哪种代理系统，工具都可能是代理的重要组成部分。 [工具](https://www.anthropic.com/news/tool-use-ga) 使 Claude 能够通过在我们的 API 中指定外部服务和 API 的确切结构和定义来与外部服务和 API 进行交互。当 Claude 响应时，如果它计划调用某个工具，它将在 API 响应中包含一个工具使用块。工具定义和规范应该像整体提示一样得到及时的工程关注。在这个简短的附录中，我们描述了如何提示设计您的工具。

通常有多种方法来指定相同的操作。例如，您可以通过写入差异或重写整个文件来指定文件编辑。对于结构化输出，您可以在 markdown 或 JSON 中返回代码。在软件工程中，此类差异是表面性的，可以无损地从一种差异转换为另一种差异。然而，对于法学硕士来说，某些格式比其他格式更难编写。编写差异需要知道在编写新代码之前块头中有多少行发生了变化。在 JSON 中编写代码（与 Markdown 相比）需要额外转义换行符和引号。

我们对决定工具格式的建议如下：

* 在模型陷入困境之前，给它足够的标记来“思考”。
* 保持格式接近模型在互联网上自然出现的文本格式。* 确保没有格式化“开销”，例如必须准确计数数千行代码，或对其编写的任何代码进行字符串转义。

一条经验法则是考虑在人机界面 (HCI) 上投入多少精力，并计划投入同样多的精力来创建良好的代理计算机界面 (ACI)。以下是关于如何执行此操作的一些想法：

* 设身处地为模特着想。根据描述和参数，如何使用这个工具是否显而易见，或者您是否需要仔细考虑？如果是这样，那么该模型可能也是如此。好的工具定义通常包括示例用法、边缘情况、输入格式要求以及与其他工具的明确界限。
* 如何更改参数名称或描述以使事情更加明显？将此视为为团队中的初级开发人员编写出色的文档字符串。当使用许多类似的工具时，这一点尤其重要。
* 测试模型如何使用您的工具：在我们的[工作台](https://console.anthropic.com/workbench)中运行许多示例输入，以查看模型犯了哪些错误，然后进行迭代。
* [Poka-yoke](https://en.wikipedia.org/wiki/Poka-yoke) 你的工具。改变论点，这样就更难犯错误。

在为 [SWE-bench](https://www.anthropic.com/research/swe-bench-sonnet) 构建代理时，我们实际上花费了比整体提示更多的时间来优化我们的工具。例如，我们发现在代理移出根目录后，模型会在使用相对文件路径的工具时出错。为了解决这个问题，我们将工具更改为始终需要绝对文件路径，并且我们发现该模型完美地使用了这种方法。

## 下一步行动计划
- 选择一条思路在实践环境中试验，并记录结果。
- 将文中提到的最佳实践整理为团队规范。
- 对关键工具或接口进行 PoC 验证，确保集成可行性。
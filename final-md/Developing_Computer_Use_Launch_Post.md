# Developing Computer Use (Launch Post)

> 来源：https://www.anthropic.com/news/developing-computer-use


## 核心速览 (TL;DR)
        - 降价内容：
* 更新

消费者条款和隐私政策

2025 年 8 月 28 日

克劳德现在可以使用电脑了。
- [最新版本的 Claude 3.5 Sonnet](http://anthropic.com/news/3-5-models-and-computer-use) 在通过适当的软件设置运行时，可以按照用户的命令在计算机屏幕上移动光标，单击相关位置，并通过虚拟键盘输入信息，模拟人们与自己的计算机交互的方式。
- 我们认为这项目前处于公开测试阶段的技能代表了人工智能进步的重大突破。

降价内容：
* 更新

消费者条款和隐私政策

2025 年 8 月 28 日

克劳德现在可以使用电脑了。 [最新版本的 Claude 3.5 Sonnet](http://anthropic.com/news/3-5-models-and-computer-use) 在通过适当的软件设置运行时，可以按照用户的命令在计算机屏幕上移动光标，单击相关位置，并通过虚拟键盘输入信息，模拟人们与自己的计算机交互的方式。

我们认为这项目前处于公开测试阶段的技能代表了人工智能进步的重大突破。下面，我们分享一些关于开发计算机使用模型并使其更安全的研究的见解。

为什么这项新功能很重要？大量的现代工作是通过计算机进行的。让人工智能能够像人类一样直接与计算机软件交互，将解锁大量当前一代人工智能助手无法实现的应用。

在过去的几年里，强大的人工智能的发展已经达到了许多重要的里程碑——例如，执行复杂逻辑推理的能力以及查看和理解图​​像的能力。下一个前沿是计算机的使用：人工智能模型不必通过定制工具进行交互，而是能够按照指示使用基本上任何软件。

研究过程
--------------------

我们之前在工具使用和多模态方面的工作为这些新的计算机使用技能奠定了基础。操作计算机涉及查看和解释图像的能力——在本例中是计算机屏幕的图像。它还需要推理如何以及何时根据屏幕上的内容执行特定操作。结合这些能力，我们训练克劳德解释屏幕上发生的事情，然后使用可用的软件工具来执行任务。

当开发人员要求 Claude 使用一款计算机软件并为其提供必要的访问权限时，Claude 会查看用户可见内容的屏幕截图，然后计算移动光标需要垂直或水平多少像素才能单击正确的位置。训练克劳德准确计算像素至关重要。如果没有这项技能，模型很难给出鼠标命令——类似于模型经常遇到看似简单的问题，例如“‘香蕉’这个词中有多少个 A？”。

我们对克劳德在计算机使用培训中的概括速度感到惊讶，我们只使用了一些简单的软件，例如计算器和文本编辑器（出于安全原因，我们不允许模型在培训期间访问互联网）。结合克劳德的其他技能，这种训练赋予了它非凡的能力，可以将用户的书面提示转化为一系列逻辑步骤，然后在计算机上采取行动。我们观察到，当遇到障碍时，该模型甚至会自我纠正并重试任务。

尽管一旦我们取得了初步突破，随后的进展就来得很快，但我们还是经历了大量的尝试和错误才达到这一目标。我们的一些研究人员指出，开发计算机的使用与他们刚开始进入该领域时所设想的人工智能研究的“理想化”过程很接近：不断迭代并反复回到绘图板，直到取得进展。

这项研究得到了回报。目前，克劳德是最先进的模型，其使用计算机的方式与人相同，即通过查看屏幕并采取响应行动。在一项旨在测试开发人员尝试让模型使用计算机的评估中，[OSWorld](https://os-world.github.io/)，克劳德目前获得了 14.9%。这与人类水平的技能（通常为 70-75%）相去甚远，但远远高于同类中次优人工智能模型所获得的 7.7%。

确保计算机使用安全
------------------------人工智能的每一次进步都会带来新的安全挑战。计算机的使用主要是降低人工智能系统应用现有认知技能的障碍，而不是从根本上提高这些技能，因此我们对计算机使用的主要关注点是当前的危害，而不是未来的危害。我们通过评估计算机使用是否会增加[负责任的扩展政策](https://www.anthropic.com/news/announcing-our-updated-responsible-scaling-policy)中概述的边境威胁风险来证实这一点。我们发现更新后的 Claude 3.5 Sonnet，包括其新的计算机使用技能，仍处于 AI 安全级别 2，也就是说，它不需要比我们目前采取的安全措施更高标准的安全措施。

当未来的模型需要人工智能安全级别 3 或 4 的保障措施时，因为它们会带来灾难性的风险，计算机的使用可能会加剧这些风险。我们认为现在引入计算机使用可能会更好，而模型仍然只需要人工智能安全级别 2 的保障。这意味着我们可以在风险过高之前开始解决任何安全问题，而不是首次将计算机使用功能添加到具有更严重风险的模型中。

本着这种精神，我们的信任与安全团队对我们的新计算机使用模型进行了广泛的分析，以识别潜在的漏洞。他们发现的一个问题是“即时注入”——一种网络攻击，其中恶意指令被输入人工智能模型，导致其要么覆盖其先前的指令，要么执行偏离用户原始意图的意外操作。由于 Claude 可以解读连接到互联网的计算机的屏幕截图，因此它可能会暴露于包含即时注入攻击的内容。

那些在我们的公开测试版中使用电脑版克劳德的人应该采取相关的预防措施，以尽量减少此类风险。作为开发人员的资源，我们在[参考实现](https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo)中提供了进一步的指导。

与任何人工智能功能一样，用户也有可能故意滥用克劳德的计算机技能。我们的团队开发了分类器和其他方法来标记和减轻此类滥用行为。鉴于即将到来的美国选举，我们对可能被视为破坏公众对选举过程信任的企图滥用行为保持高度警惕。虽然计算机的使用还不够先进，或者无法以相对于现有能力带来更大风险的规模运行，但我们已经采取了措施来监控克劳德何时被要求参与与选举相关的活动，以及促使克劳德远离在社交媒体上生成和发布内容、注册网络域名或与政府网站互动等活动的系统。我们将不断评估和迭代这些安全措施，以在公测期间平衡克劳德的能力和负责任的使用。

计算机使用的未来
--------------------------

计算机的使用是一种完全不同的人工智能开发方法。到目前为止，LLM 开发人员已经“制作了适合模型的工具”，生成了自定义环境，其中人工智能使用专门设计的工具来完成各种任务。现在，我们可以_使模型适合工具_——克劳德可以适应我们每天使用的计算机环境。我们的目标是让克劳德采用现有的计算机软件并像人一样简单地使用它们。还有很多事情要做。尽管这是当前最先进的技术，但克劳德的计算机使用速度仍然很慢并且经常容易出错。人们经常使用计算机执行的许多操作（拖动、缩放等）克劳德还无法尝试。克劳德的屏幕视图的“翻页书”性质——截取屏幕截图并将它们拼凑在一起，而不是观察更精细的视频流——意味着它可能会错过短暂的操作或通知。

即使我们在为今天的发布会录制计算机使用演示时，我们也遇到了一些[有趣的错误](https://x.com/AnthropicAI/status/1848742761278611504)。其中，克劳德不小心点击停止了长时间运行的屏幕录制，导致所有镜头丢失。在另一张照片中，克劳德突然从我们的编码演示中休息了一下，开始仔细阅读黄石国家公园的照片。

我们期望计算机的使用将迅速改善，变得更快、更可靠，并且对于我们的用户想要完成的任务来说更有用。对于那些软件开发经验较少的人来说，它也将变得更容易实施。在每个阶段，我们的研究人员都将与我们的安全团队密切合作，以确保克劳德的新功能伴随着适当的安全措施。

我们邀请在公开测试版中尝试使用计算机的开发者[使用此表单](https://docs.google.com/forms/d/e/1FAIpQLSeD3IqITWsuepB19SEv889HsBvN9WOi6HRblPrJNyA9G7q02w/viewform)与我们联系并提供反馈，以便我们的研究人员能够继续提高这项新功能的实用性和安全性。

相关内容
----------------

### 分享我们的加州前沿人工智能透明度法案合规框架

[阅读更多](https://www.anthropic.com/news/compliance-framework-SB53)

### 与美国能源部合作开启科学发现的下一个时代

[阅读更多](https://www.anthropic.com/news/genesis-mission-partnership)

### 保护我们用户的福祉

[阅读更多](https://www.anthropic.com/news/protecting-well-being-of-users)

## 下一步行动计划
- 选择一条思路在实践环境中试验，并记录结果。
- 将文中提到的最佳实践整理为团队规范。
- 对关键工具或接口进行 PoC 验证，确保集成可行性。